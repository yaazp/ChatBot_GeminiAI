{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Instalando o SDK do Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\yasmi\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\yasmi\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pyrsa-decrypt.exe, pyrsa-encrypt.exe, pyrsa-keygen.exe, pyrsa-priv2pub.exe, pyrsa-sign.exe and pyrsa-verify.exe are installed in 'c:\\Users\\yasmi\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\yasmi\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Importar a biblioteca e configurar a API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "API_KEY = \"AIzaSyAJCJXEB4f0lRTJNOAvcFj9-SHgaIGsgkE\"\n",
    "genai.configure(api_key= API_KEY)\n",
    "\n",
    "# Set up the model\n",
    "#generation_config = {\n",
    "#  \"temperature\": 1,\n",
    "#  \"top_p\": 0.95,\n",
    "#  \"top_k\": 64,\n",
    "#  \"max_output_tokens\": 8192,\n",
    "#}\n",
    "\n",
    "#safety_settings = [\n",
    "#  {\n",
    "#    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "#    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "#  },\n",
    "#  {\n",
    "#    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "#    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "#  },\n",
    "#  {\n",
    "#    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "#    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "#  },\n",
    "#  {\n",
    "#    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "#    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "#  },\n",
    "#]\n",
    "\n",
    "#model = genai.GenerativeModel(model_name=\"gemini-1.5-pro-latest\",\n",
    "#                              generation_config=generation_config,\n",
    "#                              safety_settings=safety_settings)\n",
    "\n",
    "#convo = model.start_chat(history=[\n",
    "#])\n",
    "\n",
    "#convo.send_message(\"YOUR_USER_INPUT\")\n",
    "#print(convo.last.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Listar os modelos da AI disponíveis\n",
    "Em caso de dúvida de qual versão é a última, o atalho latest aponta direto para ela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/gemini-1.0-pro\n",
      "models/gemini-1.0-pro-001\n",
      "models/gemini-1.0-pro-latest\n",
      "models/gemini-1.0-pro-vision-latest\n",
      "models/gemini-1.5-flash-latest\n",
      "models/gemini-1.5-pro-latest\n",
      "models/gemini-pro\n",
      "models/gemini-pro-vision\n"
     ]
    }
   ],
   "source": [
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print (m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Configuração do modelo e segurança"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurações do modelo:\n",
    "\n",
    "candidate_count --> o número de respostas para um pedido (pode acontecer em algumas situações)\n",
    "temperature --> entre 0 e 1. quanto mais próximo do 1 mais criativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "    \"candidate_count\": 1,\n",
    "    \"temperature\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurações de segurança do modelo:\n",
    " \n",
    " exemplo: \n",
    " safety_settings =\n",
    " [\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "    \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
    "  },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_settings = {\n",
    "    \"HARASSMENT\": \"BLOCK_NONE\",\n",
    "    \"HATE\": \"BLOCK_NONE\",\n",
    "    \"SEXUAL\": \"BLOCK_NONE\",\n",
    "    \"DANGEROUS\":\"BLOCK_NONE\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Inicializar o modelo \n",
    "Neste caso vamos usar o 1.0 pro pois neste momento o 1.5 não aceita as configurações de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(model_name= \"gemini-1.0-pro\",\n",
    "                              generation_config = generation_config, \n",
    "                              safety_settings = safety_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=glm.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"**Conceitos Fundamentais:**\\n\\n* O que \\u00e9 Intelig\\u00eancia Artificial (IA)?\\n* Tipos de IA: aprendizado de m\\u00e1quina, aprendizado profundo, processamento de linguagem natural\\n* Algoritmos de IA e t\\u00e9cnicas de aprendizado\\n\\n**Aprendizado de M\\u00e1quina:**\\n\\n* Aprendizado supervisionado vs. n\\u00e3o supervisionado\\n* Modelos de aprendizado de m\\u00e1quina: regress\\u00e3o, classifica\\u00e7\\u00e3o, agrupamento\\n* Avalia\\u00e7\\u00e3o e sele\\u00e7\\u00e3o de modelos\\n\\n**Aprendizado Profundo:**\\n\\n* Redes neurais: estrutura e funcionamento\\n* Redes neurais convolucionais (CNNs) e redes neurais recorrentes (RNNs)\\n* Treinamento e otimiza\\u00e7\\u00e3o de redes neurais\\n\\n**Processamento de Linguagem Natural (PNL):**\\n\\n* Processamento de texto: tokeniza\\u00e7\\u00e3o, an\\u00e1lise sint\\u00e1tica, an\\u00e1lise sem\\u00e2ntica\\n* Modelos de linguagem: embeddings de palavras, modelos de transformador\\n* Gera\\u00e7\\u00e3o e tradu\\u00e7\\u00e3o de linguagem\\n\\n**Aplica\\u00e7\\u00f5es da IA:**\\n\\n* Vis\\u00e3o computacional: reconhecimento de objetos, detec\\u00e7\\u00e3o de rostos\\n* Processamento de fala: reconhecimento de fala, s\\u00edntese de fala\\n* Ve\\u00edculos aut\\u00f4nomos\\n* Assistentes virtuais e chatbots\\n* Medicina e sa\\u00fade\\n\\n**\\u00c9tica e Implica\\u00e7\\u00f5es Sociais da IA:**\\n\\n* Vi\\u00e9s e discrimina\\u00e7\\u00e3o em algoritmos de IA\\n* Privacidade e seguran\\u00e7a de dados\\n* Desemprego e desigualdade social causados pela IA\\n* Regulamenta\\u00e7\\u00e3o e governan\\u00e7a da IA\\n\\n**Recursos de Aprendizagem:**\\n\\n* Cursos online: Coursera, edX, Udemy\\n* Tutoriais e documenta\\u00e7\\u00e3o: TensorFlow, PyTorch, Keras\\n* Comunidades e f\\u00f3runs: Stack Overflow, Reddit\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": 1,\n",
      "          \"index\": 0,\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": 9,\n",
      "              \"probability\": 1,\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": 8,\n",
      "              \"probability\": 1,\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": 7,\n",
      "              \"probability\": 1,\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": 10,\n",
      "              \"probability\": 1,\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ],\n",
      "          \"token_count\": 0,\n",
      "          \"grounding_attributions\": []\n",
      "        }\n",
      "      ]\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "resposta = model.generate_content(\"Vamos aprender conteúdos sobre IA. Me dê sugestões\")\n",
    "print(resposta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Conceitos Fundamentais:**\n",
      "\n",
      "* O que é Inteligência Artificial (IA)?\n",
      "* Tipos de IA: aprendizado de máquina, aprendizado profundo, processamento de linguagem natural\n",
      "* Algoritmos de IA e técnicas de aprendizado\n",
      "\n",
      "**Aprendizado de Máquina:**\n",
      "\n",
      "* Aprendizado supervisionado vs. não supervisionado\n",
      "* Modelos de aprendizado de máquina: regressão, classificação, agrupamento\n",
      "* Avaliação e seleção de modelos\n",
      "\n",
      "**Aprendizado Profundo:**\n",
      "\n",
      "* Redes neurais: estrutura e funcionamento\n",
      "* Redes neurais convolucionais (CNNs) e redes neurais recorrentes (RNNs)\n",
      "* Treinamento e otimização de redes neurais\n",
      "\n",
      "**Processamento de Linguagem Natural (PNL):**\n",
      "\n",
      "* Processamento de texto: tokenização, análise sintática, análise semântica\n",
      "* Modelos de linguagem: embeddings de palavras, modelos de transformador\n",
      "* Geração e tradução de linguagem\n",
      "\n",
      "**Aplicações da IA:**\n",
      "\n",
      "* Visão computacional: reconhecimento de objetos, detecção de rostos\n",
      "* Processamento de fala: reconhecimento de fala, síntese de fala\n",
      "* Veículos autônomos\n",
      "* Assistentes virtuais e chatbots\n",
      "* Medicina e saúde\n",
      "\n",
      "**Ética e Implicações Sociais da IA:**\n",
      "\n",
      "* Viés e discriminação em algoritmos de IA\n",
      "* Privacidade e segurança de dados\n",
      "* Desemprego e desigualdade social causados pela IA\n",
      "* Regulamentação e governança da IA\n",
      "\n",
      "**Recursos de Aprendizagem:**\n",
      "\n",
      "* Cursos online: Coursera, edX, Udemy\n",
      "* Tutoriais e documentação: TensorFlow, PyTorch, Keras\n",
      "* Comunidades e fóruns: Stack Overflow, Reddit\n"
     ]
    }
   ],
   "source": [
    "print(resposta.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Iniciando o chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando histórico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = model.start_chat(history=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando a variável de entrada da pergunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pergunta:  Qual a capital do Japão? \n",
      "\n",
      "Resposta:  Tóquio \n",
      "\n",
      "Pergunta:  Qual a comida típica deste país? \n",
      "\n",
      "Resposta:  Sushi \n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = input(\"Esperando prompt: \")\n",
    "\n",
    "while prompt != \"fim\":\n",
    "    resposta = chat.send_message(prompt) # neste caso estamos usando a variável chat que foi criada antes\n",
    "    print(\"Pergunta: \", prompt, \"\\n\")\n",
    "    print(\"Resposta: \", resposta.text, \"\\n\")\n",
    "    prompt = input(\"Esperando prompt: \")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[parts {\n",
      "  text: \"Qual é a capital do Japão\"\n",
      "}\n",
      "role: \"user\"\n",
      ", parts {\n",
      "  text: \"Tóquio\"\n",
      "}\n",
      "role: \"model\"\n",
      ", parts {\n",
      "  text: \"qual a comida típida deste país?\"\n",
      "}\n",
      "role: \"user\"\n",
      ", parts {\n",
      "  text: \"Sushi\"\n",
      "}\n",
      "role: \"model\"\n",
      ", parts {\n",
      "  text: \"Qual a capital do Japão?\"\n",
      "}\n",
      "role: \"user\"\n",
      ", parts {\n",
      "  text: \"Tóquio\"\n",
      "}\n",
      "role: \"model\"\n",
      ", parts {\n",
      "  text: \"Qual a comida típica deste país?\"\n",
      "}\n",
      "role: \"user\"\n",
      ", parts {\n",
      "  text: \"Sushi\"\n",
      "}\n",
      "role: \"model\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(chat.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O código que você forneceu é escrito em Python.  O código é um exemplo simples de como formatar e imprimir um histórico de mensagens em Python, com os seguintes passos:\n",
    "\n",
    "1.  **Importando bibliotecas:**\n",
    "    *   `import textwrap`: importa a biblioteca `textwrap` para ajustar o texto.\n",
    "    *   `from IPython.display import display`: importa a função `display` da biblioteca `IPython.display` para exibir os resultados no Jupyter Notebook.\n",
    "    *   `from IPython.display import Markdown`: importa a função `Markdown` da biblioteca `IPython.display` para renderizar texto como Markdown.\n",
    "\n",
    "2.  **Definindo a função `to_markdown()`:**\n",
    "    *   A função `to_markdown()` converte um texto em Markdown, usando o `textwrap` para ajustar a largura da linha e a função `Markdown` para renderizar o texto em Markdown.\n",
    "\n",
    "3.  **Imprimindo o histórico:**\n",
    "    *   O loop `for` itera sobre as mensagens no histórico de bate-papo (`chat_history`).\n",
    "    *   Dentro do loop, para cada mensagem:\n",
    "        *   `display(to_markdown(...))`: chama a função `to_markdown()` para converter o texto da mensagem em Markdown e usar `display` para exibir no notebook.\n",
    "\n",
    "**Resumindo, este código formata as mensagens de um histórico de bate-papo em Markdown para renderizar na tela do Jupyter Notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> **user**:\n",
       "> Qual é a capital do Japão"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> **model**:\n",
       "> Tóquio"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> **user**:\n",
       "> qual a comida típida deste país?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> **model**:\n",
       "> Sushi"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> **user**:\n",
       "> Qual a capital do Japão?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> **model**:\n",
       "> Tóquio"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> **user**:\n",
       "> Qual a comida típica deste país?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> **model**:\n",
       "> Sushi"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Melhorando a visualização\n",
    "#Código disponível em https://ai.google.dev/tutorials/python_quickstart#import_packages\n",
    "import textwrap\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('`', '**')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "#Imprimindo o histórico\n",
    "for message in chat.history:\n",
    "  display(to_markdown(f'**{message.role}**:\\n{message.parts[0].text}'))\n",
    "print('---------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
